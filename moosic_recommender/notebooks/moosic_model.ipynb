{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moosic Modelling :: Final Iteration\n",
    "\n",
    "* MOOSIC - mood based music recommendation system\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "## MODEL SKETCH : baseline model \n",
    "\n",
    "---\n",
    "\n",
    "### Music track baseline content based recommender system by mood categories\n",
    "\n",
    "* suggests data (music) based on user's interests? or users mood?\n",
    "* insights and filter based on feature variables from our data\n",
    "* ??metric: cosine similarity to measure the similarity of tracks/genres etc\n",
    "\n",
    "<br>\n",
    "\n",
    "### Algortihms and Options\n",
    "\n",
    "* Kmeans clustering algorithm (unsupervised) (~ mini batch)\n",
    "\n",
    "* t-SNE for dimensionality reduction and visualisation based on our mood labels\n",
    "\n",
    "* cluster similarity modelling based on 1D mood indicator, valence (V) and to the 2D mood indicators, valence and energy.\n",
    "\n",
    "* baseline focus: content-based recommender system based on user input query \n",
    "    - if-else construct based on mood clusters\n",
    "    - output playlist with N = 5 randomized music track recommendations based on query\n",
    "    - mood_choices are :  get users current mood cluster and also their preffered choice for mood choice for a playlist.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "## MODEL SKETCH : main model v1\n",
    "\n",
    "---\n",
    "\n",
    "### Music track baseline content based recommender system by mood categories\n",
    "\n",
    "* suggests data (music) based on user's interests? or users mood?\n",
    "* insights and filter based on feature variables from our data\n",
    "* track_to_track similiarity computation  based on m: cosine similarity to measure the similarity of tracks\n",
    "\n",
    "<br>\n",
    "\n",
    "### Algortihms and Options\n",
    "\n",
    "* Kmeans clustering algorithm (unsupervised) ~ mini batch kmeans\n",
    "\n",
    "* t-SNE for dimensionality reduction and visualisation based on our mood labels\n",
    "\n",
    "* similarity modelling based on 2-D mood (affect) indicators, valence (V) and Energy (E)\n",
    "    - music track name clustering and similarity measure, \n",
    "    - then get mood of clusters based on the average valence of the clusters gotten from the similarity\n",
    "\n",
    "* categorical mood labels are labeled encoded (but may introduce ordering bias)\n",
    "  - will use get_dummies method to encode the mood categories next\n",
    "\n",
    "* modelling : clustering + classifying + predicting/ recommending\n",
    "  - clustering : mini-batch k-means\n",
    "  - text vectorization with TfidfVectorizer on our textual data (user preferences and mood targets )\n",
    "  - track to track similarity computation\n",
    "  - recommend random N = 5 (or top N = 5) music track based on user preferences\n",
    "\n",
    "* content (track-track) recommendation system based on users mood goal and genre choice\n",
    "  - track to track similarity matrix computation : linear kernel\n",
    "  - query data based on user's preferences and clustered data\n",
    "    - new feature that combines user preferences (mood goal and genre) : text (tdidf) vectorizer else mood vector only\n",
    "    - vectorize the strings then  compute and store similarity scores of tracks \n",
    "  - track_similarity_matrix : track to track similarity based on associated mood and genre \n",
    "  - assign track similarity matrix scores computed back to our data\n",
    "  - used linear kernel to compute similarity\n",
    "  - reset and drop index, then concatenated withh clustered data to be used for the next step\n",
    "  - classifying tracks based on similarity score and predicting random N = 5 samples\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* main focus: content-based recommender system based on user input query \n",
    "    - if-else construct based on mood clusters\n",
    "    - output playlist with N = 5 randomized music track recommendations based on query\n",
    "    - mood_choices are :  get users current mood cluster and also their preffered choice for mood choice for a playlist.\n",
    "\n",
    "\n",
    "* options (for main): \n",
    "    - svm \n",
    "    - classification/prediction of track to track to user preference scores\n",
    "    - genetic algorithm for feature selection for an ML model : search and optimization in large solution space\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow chart of thought process (v3)\n",
    "\n",
    "\n",
    "![Flow chart for model idea iteration v3](/images/moosic_process_current_workflow.jpeg)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Importing required libraries\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# IMPORT LIBRARIES\n",
    "\n",
    "\n",
    "try:\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import random as rnd\n",
    "    #from tqdm.notebook import tqdm as tqdm\n",
    "    from tqdm import tqdm \n",
    "    #from .autonotebook import tqdm as notebook_tqdm\n",
    "    import time\n",
    "\n",
    "    # databases - sql\n",
    "    #from dotenv import dotenv_values\n",
    "    #import sqlalchemy\n",
    "\n",
    "    # visualisation\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.colors import ListedColormap\n",
    "\n",
    "    # split data - avoid data leakage\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "    # cross validation, hyperparameter tuning\n",
    "    from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, KFold\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    # preprocessing, scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "    # modelling - clustering\n",
    "    from sklearn.cluster import KMeans, MiniBatchKMeans, MeanShift, DBSCAN\n",
    "    from kmodes.kmodes import KModes\n",
    "    from kmodes.kprototypes import KPrototypes\n",
    "\n",
    "    # text converter/ vectorizer\n",
    "    from sklearn.feature_extraction.text  import TfidfVectorizer\n",
    "\n",
    "    # modelling - classification\n",
    "    from xgboost import XGBClassifier\n",
    "    from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "    from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    # high dimensional usage - dimensionality reduction\n",
    "    from sklearn.manifold import TSNE\n",
    "    from sklearn.decomposition import PCA\n",
    "    from umap import UMAP\n",
    "\n",
    "    # metrics\n",
    "    from sklearn import metrics\n",
    "    from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "    from sklearn.metrics import classification_report, confusion_matrix, roc_curve\n",
    "    from sklearn.metrics.pairwise import cosine_similarity, linear_kernel\n",
    "    from sklearn.metrics import adjusted_rand_score, silhouette_score, v_measure_score, ndcg_score, precision_score, \\\n",
    "        recall_score, f1_score, average_precision_score\n",
    "\n",
    "    # pipeline\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "except ImportError as error:\n",
    "    print(f\"Installation of the required dependencies necessary! {error}\")\n",
    "\n",
    "    %pip install numpy\n",
    "    %pip install pandas\n",
    "    #%pip install dotenv\n",
    "    #%pip install sqlalchemy\n",
    "    %pip install seaborn\n",
    "    %pip install matplotlib\n",
    "    %pip install scikit-learn\n",
    "    %pip install xgboost\n",
    "    %pip install tqdm\n",
    "    %pip install ipywidgets\n",
    "    print(f\"Successful installation of the required dependencies necessary\")\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# color scheme\n",
    "\n",
    "- custom_palette = { violet: #2B2960, blue: #00A1D8, orange: #F08144, yellow: #FDC20C, green: #29A744, eggshell: #FFF4D5}\n",
    "\n",
    "\n",
    "- custom_palette =[#2B2960, #00A1D8, #F08144, #FDC20C, #29A744, #FFF4D5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting color scheme for plots\n",
    "\n",
    "\n",
    "hex_colors = ['#2B2960', '#00A1D8', '#F08144', '#FDC20C', '#29A744', '#22E87E', '#FFF4D5', '#E3CFBF']\n",
    "\n",
    "custom_palette = sns.set_palette(sns.color_palette(hex_colors))\n",
    "\n",
    "# pandas plot: colormap = custom_cmap_hex, plt/sns plot : cmap = custom_cmap_hex\n",
    "custom_cmap_hex1 = ListedColormap(sns.color_palette(hex_colors).as_hex())\n",
    "\n",
    "custom_cmap_hex1 \n",
    "\n",
    "# pandas plot: colormap = custom_cmap_hex, plt/sns plot : cmap = custom_cmap_hex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# euphoric = #FFF2CC, happy = #FFD966, tense = #E99999, angry = #DD7E6B, depressed = #A2C4C9, sad = #76A5AF, relaxed = #B5D7A8, calm = #D9EAD3,\n",
    "hex_colors_quad = ['#ecd07a', '#FFD966', '#E99999', '#DD7E6B', '#A2C4C9', '#76A5AF', '#B5D7A8', '#D9EAD3']\n",
    "custom_cmap_quad = ListedColormap(sns.color_palette(hex_colors_quad).as_hex())\n",
    "\n",
    "custom_cmap_quad \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moosic_data_all = pd.read_csv('../../data/processed/moosic_data_processed.csv', low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the modelling data file for moosic with all music track samples\n",
    "\n",
    "moosic_data_all = pd.read_csv('../../data/processed/moosic_data_processed.csv', low_memory=False)\n",
    "\n",
    "# get shape \n",
    "\n",
    "print(f\"Music data: There are {moosic_data_all.shape[0]} observations and {moosic_data_all.shape[1]} feature variables \")\n",
    "print('----------'*10)\n",
    "\n",
    "moosic_data_all.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of moods - all tracks\n",
    "\n",
    "moosic_data_all.groupby('mood_goal')['mood_goal'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset is unbalanced from the perspective of the associated mood \n",
    "#    get the count of how the mood is distributed wrt the data\n",
    "# get sample size = 15000 #20000\n",
    "\n",
    "def get_balanced_data(processed_dataset, sample_size = 20000):\n",
    "\n",
    "    ''' \n",
    "    get data with specified sample size based on each mood?\n",
    "        \n",
    "    '''\n",
    "\n",
    "    sampled_moosic_data  = pd.DataFrame()\n",
    "    grouped_data = processed_dataset.groupby('mood_goal')\n",
    "\n",
    "\n",
    "    for mood_label, group in grouped_data:\n",
    "        \n",
    "        #print(f' getting data samples for the mood : {mood_label} \\n ')\n",
    "\n",
    "        if len(group) >= sample_size: \n",
    "            random_rows = group.sample(sample_size, random_state=42) \n",
    "        else:\n",
    "            random_rows = group  \n",
    "\n",
    "        sampled_moosic_data = pd.concat([sampled_moosic_data, random_rows])\n",
    "\n",
    "        continue\n",
    "\n",
    "    print(f' Finished processing, data has balanced number of samples for all categories. ')\n",
    "\n",
    "    sampled_moosic_data = sampled_moosic_data.reset_index(drop=True) \n",
    "\n",
    "    mood_label_counts = sampled_moosic_data['mood_goal'].value_counts()\n",
    "    print(f\"The size of data mood label count {mood_label_counts} \")\n",
    "    print(\"______\"*10)\n",
    "\n",
    "    return sampled_moosic_data\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## display balanced moosic : mood-music data\n",
    "\n",
    "moosic_data_samples = get_balanced_data(moosic_data_all, sample_size = 15000)\n",
    "moosic_data_samples = pd.concat([moosic_data_samples.drop(['main_genres','core_genres','genres'], axis = 1),\n",
    "        pd.concat([moosic_data_samples['core_genres'], pd.get_dummies(moosic_data_samples['core_genres'], drop_first=True).replace({True: 1, False: 0})], axis = 1) ], axis=1)\n",
    "\n",
    "\n",
    "print(f\"Music data: There are {moosic_data_samples.shape[0]} observations and {moosic_data_samples.shape[1]} feature variables \")\n",
    "print('----------'*10)\n",
    "\n",
    "moosic_data_samples.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Splitting the dataset for modelling : \n",
    "\n",
    "* train, test split : splitting the data to avoid data leakage \n",
    "* drop columns = ['artist_id', 'track_id' , 'artist_name',  'track_name', 'core_genres']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# all features\n",
    "all_features = ['artists_id' , 'track_id', 'artist_name', 'track_name', 'genres', 'danceability','energy', 'key', 'speechiness', 'acousticness', \n",
    "                        'release_date', 'explicit', 'key', 'loudness', 'mode', 'time_signature', 'followers', 'classical', 'country', 'instrumentalness'\n",
    "                        'artist_popularity',  'track_popularity', 'tempo', 'main_genres', 'core_genres', 'mood_goal', 'blues', 'classical', 'country', \n",
    "                        'disco', 'dubstep', 'edm','electronic', 'folk', 'funk', 'gospel', 'hip hop', 'house', 'indie rock', 'jazz', 'metal', 'other', \n",
    "                        'pop', 'punk rock', 'r&b', 'reggae', 'rock','rockabilly','soul', 'techno']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function to split dataset for modelling \n",
    "# splitting dataset and also retain specific features to be outputted\n",
    "\n",
    "def split_dataset(dataset, target_feature = 'mood_goal', input_features = ['track_id', 'valence','energy', 'mood_goal'],  \n",
    "                        drop_features = ['track_id'], output_features = ['track_id', 'mood_goal']): \n",
    "\n",
    "    ## get list of moosic data features\n",
    "    #features = dataset.columns.tolist()\n",
    "\n",
    "    # defining X (input feature vectors) and Y (target output features)\n",
    "\n",
    "\n",
    "    X_data = dataset[input_features]\n",
    "\n",
    "    y_data = dataset['mood_goal']\n",
    "\n",
    "\n",
    "    # splitting the dataset into train and test\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.20, random_state=42, shuffle=True, stratify=y_data)\n",
    "\n",
    "    Y_train = X_train[output_features].reset_index(drop=True)\n",
    "    Y_test = X_test[output_features].reset_index(drop=True)\n",
    "\n",
    "    X_train = X_train[input_features].drop(drop_features, axis=1).reset_index(drop=True)\n",
    "    X_test =  X_test[input_features].drop(drop_features, axis=1).reset_index(drop=True)\n",
    "\n",
    "    y_train = Y_train[target_feature].reset_index(drop=True)\n",
    "    y_test = Y_test[target_feature].reset_index(drop=True)\n",
    "\n",
    "    data  = {\n",
    "        'X_data':X_data,\n",
    "        'y_data':y_data,\n",
    "        'X_train':X_train,\n",
    "        'X_test':X_test,\n",
    "        'y_train':y_train,\n",
    "        'y_test':y_test,        \n",
    "        'Y_train':Y_train,\n",
    "        'Y_test':Y_test,\n",
    "        }\n",
    "\n",
    "    return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#sample_size = 20000\n",
    "\n",
    "mood_categories = ['angry', 'calm', 'depressed', 'euphoric', 'happy', 'relaxed', 'sad', 'tense']\n",
    "\n",
    "# baseline_features = moosic_data.columns.tolist()\n",
    "\n",
    "# all features\n",
    "all_features = ['artists_id' , 'track_id', 'artist_name', 'track_name', 'genres', 'danceability','energy', 'key', 'speechiness', 'acousticness', \n",
    "                        'release_date', 'explicit', 'key', 'loudness', 'mode', 'time_signature', 'followers', 'classical', 'country', 'instrumentalness'\n",
    "                        'artist_popularity',  'track_popularity', 'tempo', 'main_genres', 'core_genres', 'mood_goal', 'blues', 'classical', 'country', \n",
    "                        'disco', 'dubstep', 'edm','electronic', 'folk', 'funk', 'gospel', 'hip hop', 'house', 'indie rock', 'jazz', 'metal', 'other', \n",
    "                        'pop', 'punk rock', 'r&b', 'reggae', 'rock','rockabilly','soul', 'techno']\n",
    "\n",
    "\n",
    "#features to be dropped\n",
    "drop_features = ['track_id', 'track_name', 'artist_name',  'core_genres', 'mood_goal', 'release_date']\n",
    "\n",
    "\n",
    "# feature columns\n",
    "baseline_input_features = ['track_id', 'track_name', 'artist_name',  'core_genres', 'mood_goal','danceability', 'valence', 'tempo','energy', \n",
    "                        'release_date', 'key', 'speechiness', 'acousticness', 'instrumentalness',  'loudness', 'mode', 'time_signature',\n",
    "                        'blues', 'classical', 'country', 'disco', 'dubstep', 'edm','electronic', 'folk', 'funk', 'gospel', 'hip hop', 'house', 'indie rock', \n",
    "                        'jazz', 'metal', 'other', 'pop', 'punk rock', 'r&b', 'reggae', 'rock','rockabilly','soul', 'techno']\n",
    "\n",
    "\n",
    "# features to be outputed by the recommender at the end\n",
    "output_features = ['track_id', 'track_name', 'artist_name',  'core_genres', 'mood_goal']\n",
    "\n",
    "\n",
    "# target column\n",
    "target_feature = 'mood_goal'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data splits\n",
    "# n=15\n",
    "\n",
    "\n",
    "\n",
    "moosic_data_nk = split_dataset(moosic_data_samples, target_feature = target_feature,\n",
    "                        input_features = baseline_input_features,  output_features = output_features,\n",
    "                            drop_features=drop_features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X features (input):  X_train, X_test\n",
    "# Y features (output):  Y_train, Y_test\n",
    "# y feature (target):  y_train, y_test\n",
    "\n",
    "\n",
    "print(\"X train (input features) \")\n",
    "print(\"-----\"*10)\n",
    "X_train = moosic_data_nk['X_train']\n",
    "display(X_train.head(2))\n",
    "\n",
    "print(\"X test (input features) \")\n",
    "print(\"-----\"*10)\n",
    "X_test = moosic_data_nk['X_test']\n",
    "display(X_test.head(2))\n",
    "\n",
    "\n",
    "print(\"Y train (target output features) \")\n",
    "print(\"-----\"*10)\n",
    "Y_train = moosic_data_nk['Y_train']\n",
    "display(Y_train.head(2))\n",
    "\n",
    "\n",
    "print(\"Y test (target output features) \")\n",
    "print(\"-----\"*10)\n",
    "Y_test = moosic_data_nk['Y_test']\n",
    "display(Y_test.head(2))\n",
    "\n",
    "\n",
    "print(\"y train (target feature) \")\n",
    "print(\"-----\"*10)\n",
    "y_train = moosic_data_nk['y_train']\n",
    "display(y_train.head(2))\n",
    "\n",
    "\n",
    "print(\"y test (target feature) \")\n",
    "print(\"-----\"*10)\n",
    "y_test = moosic_data_nk['y_test']\n",
    "display(y_test.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Modelling\n",
    "\n",
    "* elbow method\n",
    "* dimensionality reduction / visualization of clusters in lower (2d) dimension\n",
    "* clustering\n",
    "* (?!)visualization of clusters in lower (2d) dimension\n",
    "* prediction/classification (multi-class classification) models ... multi-label?\n",
    "* recommender :top n = 5 based on item-item similarity computation based on clustering\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def optimal_cluster_plot(data, tsne=True):\n",
    "\n",
    "    wcss_inertias = []\n",
    "\n",
    "    if tsne == True:\n",
    "        tsne = TSNE(n_components=2)\n",
    "        data = tsne.fit_transform(data)\n",
    "\n",
    "    else:\n",
    "        data = data\n",
    "\n",
    "    for k in range(4, 20):\n",
    "        model = MiniBatchKMeans(n_clusters=k)\n",
    "        model.fit(data)\n",
    "        wcss_inertias.append(model.inertia_)\n",
    "        \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "    ax.plot(range(4, 20), wcss_inertias, '-o')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('WCSS : Within clusters sum of squares')\n",
    "    plt.title('Elbow method to determine optimal K number of clusters')\n",
    "    plt.xticks(range(4, 20))\n",
    "    plt.show(); \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# optimal number of clusters using elbow method analysis to compare with the researched  basic number of moods for music (8)\n",
    "\n",
    "optimal_cluster_plot(X_train, tsne=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X_train[['valence',  'energy']]\n",
    "optimal_cluster_plot(data, tsne=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without tsne\n",
    "\n",
    "optimal_cluster_plot(X_train, tsne=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function clustering model (+ tsne) \n",
    "\n",
    "\n",
    "def clustering_model(data,  pca = True, tsne=True, params = {'n_clusters': 8}, sample_size=5000, *args, **kwargs):\n",
    "\n",
    "\n",
    "    data = data.head(sample_size)\n",
    "    scaled_data = MinMaxScaler().fit_transform(data)\n",
    "    data_col = data.columns.to_list()\n",
    "    data = pd.DataFrame(scaled_data, columns = data_col)\n",
    "\n",
    "    if pca == True:\n",
    "        pca = PCA(n_components=2, random_state = 42)\n",
    "\n",
    "        pca_start_time = time.time()\n",
    "\n",
    "        data = MinMaxScaler().fit_transform(pca.fit_transform(data))\n",
    "\n",
    "        pca_end_time = time.time()\n",
    "        pca_train_time = pca_end_time - pca_start_time\n",
    "        print(f\"Time taken for dimensionality reduction using PCA: {pca_train_time:.2f} seconds\")\n",
    "\n",
    "        data = pd.DataFrame(data, columns = ['dimension_0', 'dimension_1'])\n",
    "\n",
    "    else:\n",
    "        data = data\n",
    "\n",
    "\n",
    "    model = MiniBatchKMeans(**params)\n",
    "\n",
    "    kme_start_time = time.time()\n",
    "\n",
    "    data['cluster_labels'] = model.fit_predict(data)\n",
    "\n",
    "    kme_end_time = time.time()\n",
    "    kme_train_time = kme_end_time - kme_start_time\n",
    "    \n",
    "\n",
    "    cluster_labels = model.labels_ \n",
    "    cluster_centers = model.cluster_centers_ \n",
    "\n",
    "    #if tsne == True:\n",
    "    tsne = TSNE(n_components=2, random_state = 42)\n",
    "\n",
    "    tsne_start_time = time.time()\n",
    "\n",
    "    tsne_embeddings = tsne.fit_transform(data)\n",
    "\n",
    "    tsne_end_time = time.time()\n",
    "    tsne_train_time = tsne_end_time - tsne_start_time\n",
    "        \n",
    "\n",
    "    #else:\n",
    "    #    data = data\n",
    "\n",
    "\n",
    "    \n",
    "    # kp_model_name = \"minikmeans.pickle\"\n",
    "    # tp_model_name = \"tsne_embed.pickle\"\n",
    "\n",
    "    # pickle.dump(model, open(kp_model_name, 'wb'))\n",
    "    # pickle.dump(model, open(tp_model_name, 'wb'))\n",
    "\n",
    "\n",
    "    # kj_model_name = \"minikmeans.joblib\"\n",
    "    # tj_model_name = \"tsne_embed.joblib\"\n",
    "\n",
    "    # joblib.dump(model, kj_model_name)\n",
    "    # joblib.dump(model, tj_model_name)\n",
    "\n",
    "\n",
    "\n",
    "    return data, tsne_embeddings, cluster_labels, cluster_centers\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# defining the actual y (target data - mood_goal)\n",
    "# y : y_train, y_test\n",
    "\n",
    "\n",
    "# encode categorical data : mood\n",
    "y_train_dummies = pd.get_dummies(y_train, drop_first=True).replace({True: 1, False: 0})\n",
    "encoded_y_train = pd.concat([y_train, y_train_dummies], axis=1)\n",
    "\n",
    "y_test_dummies = pd.get_dummies(y_test, drop_first=True).replace({True: 1, False: 0})\n",
    "encoded_y_test = pd.concat([y_test, y_test_dummies], axis=1)\n",
    "\n",
    "\n",
    "print(\"encoded target (train) data - mood_goal \")\n",
    "print(\"-----\"*10)\n",
    "display(encoded_y_train.head(2))\n",
    "\n",
    "\n",
    "print(\"encoded target (test) data - mood_goal \")\n",
    "print(\"-----\"*10)\n",
    "display(encoded_y_test.head(2))\n",
    "\n",
    "\n",
    "#mood_labels = [\"depressed\", \"sad\", \"anxious\",  \"neutral\", \"calm\", \"euphoric\", \"energetic\", \"happy\"]\n",
    "#mood_1d_class = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "\n",
    "# add targets for evaluation for clusters later\n",
    "\n",
    "#moosic_data[\"mood_label\"] = (pd.cut(moosic_data[\"valence\"], bins=mood_valence_values, labels=mood_1d_labels)).astype('string')\n",
    "#moosic_data[\"mood_class\"] = (pd.cut(moosic_data[\"valence\"], bins=mood_valence_values, labels=mood_1d_class)).astype('Int64')\n",
    "\n",
    "#moosic_data.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking clustered data features\n",
    "\n",
    "clustered_data, clustered_embeddings, cluster_labels, cluster_centers = clustering_model(X_train,  pca = False, tsne = True, \n",
    "                                                                        params = {'n_clusters': 8}, sample_size = 5000)\n",
    "\n",
    "clustered_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline: recommendation based on predictions of music track (mood-genre groups) and recommendation\n",
    "# - mood labels are labeled encoded (but may introduce ordering bias)\n",
    "## * --> np.unique(y_train['mood_2d_label'].copy()) = ['angry' 'calm' 'depressed' 'euphoric' 'happy' 'relaxed' 'sad' 'tense']\n",
    "## * --> np.unique(LabelEncoder().fit_transform(y_train[['mood_2d_label']]).copy()) = array([0, 1, 2, 3, 4, 5, 6, 7])\n",
    "## * --> np.concatenate([b, c]).tolist() =  ['angry','calm','depressed','euphoric','happy','relaxed','sad','tense',0,1,2,3,4,5,6,7]\n",
    "#mood_list_types = ['angry','calm','depressed','euphoric','happy','relaxed','sad','tense', 0, 1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "\n",
    "baseline_cluster_params = {\n",
    "    'n_clusters' : 8,\n",
    "    'batch_size' : 500,\n",
    "    'random_state' : 42,\n",
    "    'init' : 'k-means++' #random\n",
    "}\n",
    "\n",
    "\n",
    "mood_clusters  = {\n",
    "                        'happy' : 4,\n",
    "                        'euphoric' : 3,                  \n",
    "                        'tense' : 7, \n",
    "                        'angry' :0, \n",
    "                        'depressed' : 2, \n",
    "                        'sad' :6, \n",
    "                        'calm' : 1, \n",
    "                        'relaxed' : 5\n",
    "\n",
    "    }\n",
    "\n",
    "\n",
    "def baseline_clustering(x_train,  mood_clusters = mood_clusters, cluster_params = baseline_cluster_params,\n",
    "                        pca=False, tsne=True, sample_size = 10000,  *args, **kwargs):\n",
    "\n",
    "\n",
    "    # clustering with mini-batch kmeans \n",
    "    clustered_data, clustered_embeddings, cluster_labels, cluster_centers = clustering_model(x_train,  pca = pca, tsne = tsne, \n",
    "                                                                        params = cluster_params)\n",
    "\n",
    "    #feature matrix of one-hot encoded cluster representation\n",
    "    feature_matrix = np.eye(cluster_params['n_clusters'])[cluster_labels]\n",
    "\n",
    "    #track_similarity_matrix = 1 - pairwise_distances(clustered_data, cluster_centers, metric='cosine')\n",
    "\n",
    "\n",
    "\n",
    "    #print(\"________\"*20)\n",
    "    #print(\"________\"*20)\n",
    "\n",
    "    # visualize the clustered data\n",
    "    fig, ax = plt.subplots(figsize = (16, 10))\n",
    "    # fig, ax = plt.subplots()\n",
    "    # fig, ax = plt.figure()\n",
    "\n",
    "    scaled_embed = MinMaxScaler().fit_transform(clustered_embeddings)\n",
    "    plt.scatter(scaled_embed[:, 0], scaled_embed[:, 1], c=cluster_labels, cmap=custom_cmap_quad)\n",
    "    #plt.scatter(cluster_centers[:, 0], cluster_centers[:, 1], marker='X', color='black') \n",
    "\n",
    "    # for cluster_centerx, cluster_centery in zip(cluster_centers[:, 0], cluster_centers[:, 1]):\n",
    "\n",
    "    #    plt.scatter(cluster_centerx, cluster_centery, marker='X', color='black') \n",
    "\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title('Music - Mood Clustered Data ', pad=15, fontsize = 20, weight = 'bold', color='#928d8d')#'#C3C7C5')\n",
    "    plt.colorbar()\n",
    "\n",
    "    get_axes = plt.gca()\n",
    "    plt.xticks([]) \n",
    "    plt.yticks([]) \n",
    "    xax = get_axes.axes.get_xaxis()\n",
    "    \n",
    "    xax = xax.set_visible(False)\n",
    "\n",
    "    yax = get_axes.axes.get_yaxis()\n",
    "    yax = yax.set_visible(False)\n",
    "\n",
    "    # Set the axis colors\n",
    "    ax.set_facecolor('#F7F3F0') #E2E2DB\n",
    "    ax.grid(color='#cfcecb')\n",
    "    ax.set_facecolor('#eeeeee') #eeeeee\n",
    "    ax.spines['bottom'].set_color('#eeeeee')\n",
    "    ax.spines['top'].set_color('#eeeeee')\n",
    "    ax.spines['right'].set_color('#eeeeee')\n",
    "    ax.spines['left'].set_color('#eeeeee')\n",
    "    ax.xaxis.label.set_color('#eeeeee')\n",
    "    ax.yaxis.label.set_color('#eeeeee')\n",
    "\n",
    "    plt.show()\n",
    "    plt.savefig('../images/1_clusters_count_plot.png', transparent=True)\n",
    "\n",
    "    return clustered_data, clustered_embeddings, scaled_embed\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(Y_train['mood_goal'].copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mood_clusters  = {\n",
    "#                         'happy' : 4,\n",
    "#                         'euphoric' : 3,                  \n",
    "#                         'tense' : 7, \n",
    "#                         'angry' :0, \n",
    "#                         'depressed' : 2, \n",
    "#                         'sad' :6, \n",
    "#                         'calm' : 1, \n",
    "#                         'relaxed' : 5\n",
    "\n",
    "#     }\n",
    "\n",
    "\n",
    "mood_clusters  = {\n",
    "                'relaxed' : 0,\n",
    "                'happy' : 1,\n",
    "                'euphoric' : 2,\n",
    "                'depressed' : 3, \n",
    "                'sad' :4,  \n",
    "                'calm' : 5,                                          \n",
    "                'tense' : 6, \n",
    "                'angry' :7\n",
    "    }\n",
    "\n",
    "#mood_list_types = list(mood_clusters.items())\n",
    "mood_list_types = [item for sublist in mood_clusters.items() for item in sublist]\n",
    "\n",
    "mood_list_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mood_labels = [\"relaxed\", \"happy\", \"euphoric\", \"depressed\", \"sad\",  \"calm\", \"tense\",  \"angry\", ]\n",
    "# mood_cat_values = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "\n",
    "# # add targets for evaluation for clusters later\n",
    "\n",
    "# moosic_data[\"mood_label\"] = (pd.cut(moosic_data[\"mood_labels\"], bins=mood_valence_values, labels=mood_1d_labels)).astype('string')\n",
    "# moosic_data[\"mood_class\"] = (pd.cut(moosic_data[\"valence\"], bins=mood_valence_values, labels=mood_1d_class)).astype('Int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run baseline\n",
    "# - run clustering model : kmeans/ mini-batch kmeans\n",
    "# - dimensionality reduction and visualization with tsne\n",
    "# - query clustered data and output N = 5 recommendations\n",
    "# - final data shows music track name and its associated, artist, mood goal/group, core genre, and its K clustered labels.\n",
    "\n",
    "# mood_clusters  = {\n",
    "#                         'happy' : [(0.5, 1.0), (0.5, 0.75)],\n",
    "#                         'euphoric' : [(0.5, 1.0), (0.75, 1.0)],                  \n",
    "#                         'tense' : [(0.0, 0.5), (0.75, 1.0)], \n",
    "#                         'angry' :[(0.0, 0.5), (0.5, 0.75)], \n",
    "#                         'depressed' : [(0.0, 0.5), (0.25, 0.5)], \n",
    "#                         'sad' :[(0.0, 0.5), (0.0, 0.25)], \n",
    "#                         'calm' : [(0.5, 1.0), (0.0, 0.25)], \n",
    "#                         'relaxed' : [(0.5, 1.0), (0.25, 0.5)]\n",
    "\n",
    "#     }\n",
    "\n",
    "\n",
    "mood_clusters  = {\n",
    "                        'happy' : 4,\n",
    "                        'euphoric' : 3,                  \n",
    "                        'tense' : 7, \n",
    "                        'angry' :0, \n",
    "                        'depressed' : 2, \n",
    "                        'sad' :6, \n",
    "                        'calm' : 1, \n",
    "                        'relaxed' : 5\n",
    "\n",
    "    }\n",
    "\n",
    "\n",
    "clustered_data, clustered_embeddings, scaled_embeddings = baseline_clustering(X_train,  mood_clusters = mood_clusters, cluster_params = baseline_cluster_params,\n",
    "                        pca=False, tsne=True, sample_size = 15000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# recommend top N = 5 or random N = 5 music track based on user preferences\n",
    "def baseline_recommender(clustered_data, y_train, clustered_embeddings, scaled_embed, user_preferences = {'mood_goal': 'relaxed', 'preferred_genre': 'hip hop'}, \n",
    "                        playlist_length= 5, mood_clusters = mood_clusters, *args, **kwargs):\n",
    "\n",
    "\n",
    "    recommender_start_time = time.time()\n",
    "\n",
    "    # recommender: query data based on user's preferences and clustered data\n",
    "\n",
    "\n",
    "    y_train_classes = np.unique(y_train['mood_goal'].copy())\n",
    "    y_train_classes_encoded = LabelEncoder().fit_transform(y_train[['mood_goal']]).copy()\n",
    "    mood_list_types = np.concatenate([y_train_classes, np.unique(y_train_classes_encoded)]).tolist()\n",
    "    y_train['mood_label'] = y_train_classes_encoded\n",
    "\n",
    "    #y_train['mood_label'] = y_train.replace({'relaxed' : 0, 'happy' : 1,'euphoric' : 2, 'depressed' : 3, \n",
    "    #           'sad' :4,  'calm' : 5,  'tense' : 6, 'angry' :7})\n",
    "\n",
    "    #mood_list_types = [item for sublist in mood_clusters.items() for item in sublist]\n",
    "\n",
    "    final_data = pd.concat([ y_train[['track_id', 'track_name', 'artist_name', 'mood_goal', 'core_genres', 'mood_label' ]], clustered_data['cluster_labels']], axis=1)\n",
    "\n",
    "    if (user_preferences['mood_goal'] in mood_list_types): #and (user_preferences['preferred_genre'] in mood_list_types):    \n",
    "        choice = mood_clusters[user_preferences['mood_goal']]\n",
    "        query_data = final_data.query(\"cluster_labels == @choice\") \n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Input mood goal is unavailable .... specified only! \")\n",
    "\n",
    "    #print(\"________\"*20)\n",
    "    #print(\"________\"*20)\n",
    "\n",
    "\n",
    "    print(f\"Recommended music tracks based on {user_preferences['mood_goal']}: \\n \")\n",
    "    print(\"________\"*15)\n",
    "\n",
    "    #print(f\" Enjoy these {playlist_length} music tracks from spotify\")\n",
    "    #print(\"             \"*10)\n",
    "\n",
    "    #recommended_moosic_playlist = query_data.sample(n=playlist_length, random_state = 42, replace=False)\n",
    "\n",
    "    #print(\"________\"*10)\n",
    "    moosic_randomN_idx = np.random.choice(\n",
    "                            query_data.index,\n",
    "                            size = 5, #playlist_length,\n",
    "                            replace= False #random n = 5\n",
    "                            )\n",
    "    \n",
    "    recommended_moosic_playlist = final_data.iloc[moosic_randomN_idx]\n",
    "\n",
    "\n",
    "    recommender_end_time = time.time()\n",
    "    recommender_train_time = recommender_end_time - recommender_start_time\n",
    "    print(f\"Time taken for the recommender model : {recommender_train_time:.2f} seconds\")\n",
    "\n",
    "    #print(\"________\"*20)\n",
    "    #print(\"________\"*20)\n",
    "\n",
    "    return final_data, recommended_moosic_playlist\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# baseline recommender\n",
    "final_data, n_mood_music = baseline_recommender(clustered_data, Y_train, clustered_embeddings, scaled_embeddings, user_preferences = {'mood_goal': 'relaxed', 'preferred_genre': 'pop'}, \n",
    "                        playlist_length= 5, mood_clusters = mood_clusters)\n",
    "\n",
    "\n",
    "# display recommendations\n",
    "n_mood_music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.groupby('mood_goal')[['mood_goal']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#groups = final_data.groupby('cluster_labels')[['mood_label', 'cluster_labels']].value_counts()\n",
    "\n",
    "#groups.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "\n",
    "\n",
    "* tracks count grouped by cluster labels\n",
    "\n",
    "``````\n",
    "{0.0: 603,\n",
    " 1.0: 679,\n",
    " 2.0: 1278,\n",
    " 3.0: 792,\n",
    " 4.0: 146,\n",
    " 5.0: 244,\n",
    " 6.0: 293,\n",
    " 7.0: 965}\n",
    "``````\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation metrics : clustering\n",
    "\n",
    "\n",
    "def cluster_evaluation_metrics(ground_truth, predictions, silhouette=True):\n",
    "    \n",
    "    if silhouette == False:\n",
    "        clustering_metrics = [\n",
    "                # (n_samples, )\n",
    "                metrics.rand_score,\n",
    "                metrics.fowlkes_mallows_score,\n",
    "                metrics.homogeneity_score,\n",
    "                metrics.completeness_score,\n",
    "                metrics.v_measure_score,\n",
    "                metrics.mutual_info_score,\n",
    "                metrics.adjusted_rand_score,\n",
    "                metrics.adjusted_mutual_info_score\n",
    "            ]\n",
    "\n",
    "        for metric in clustering_metrics:\n",
    "            score_class = metric(ground_truth.to_numpy(), predictions.to_numpy())\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        cluster_scores_metrics = [\n",
    "                # (n_samples, 1)\n",
    "                metrics.silhouette_score,\n",
    "                metrics.calinski_harabasz_score,\n",
    "            ]\n",
    "\n",
    "\n",
    "        for metric in cluster_scores_metrics:\n",
    "            score_class = metric(ground_truth.to_numpy().reshape(-1,1), predictions.to_numpy().reshape(-1,1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display final dataset for all clustered samples\n",
    "\n",
    "final_data.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop null/empty rows\n",
    "\n",
    "null_rows11 = final_data[final_data.isnull().T.any()].index\n",
    "final_data = final_data.drop(null_rows11)\n",
    "empty_values = final_data.isna().sum()\n",
    "print(empty_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation metrics\n",
    "\n",
    "\n",
    "print(metrics.rand_score(final_data['mood_label'], final_data['cluster_labels']))\n",
    "\n",
    "print(metrics.cluster.adjusted_rand_score(final_data['mood_label'], final_data['cluster_labels']))\n",
    "\n",
    "print(metrics.homogeneity_score(final_data['mood_label'], final_data['cluster_labels']))\n",
    "\n",
    "\n",
    "print(metrics.completeness_score(final_data['mood_label'], final_data['cluster_labels']))\n",
    "\n",
    "\n",
    "print(metrics.v_measure_score(final_data['mood_label'], final_data['cluster_labels']))\n",
    "\n",
    "print(metrics.silhouette_score(final_data['mood_label'].to_numpy().reshape(-1,1), final_data['cluster_labels'].to_numpy().reshape(-1,1)))\n",
    "\n",
    "print(metrics.mutual_info_score(final_data['mood_label'], final_data['cluster_labels']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Main model \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_input_features = ['track_id', 'track_name', 'artist_name',  'core_genres', 'mood_goal','danceability', 'release_date',\n",
    "                    'valence', 'energy',  'tempo', 'acousticness', 'instrumentalness', #'key', 'loudness',\n",
    "                    'blues', 'classical', 'country', 'disco', 'dubstep', 'edm','electronic', \n",
    "                    'folk', 'funk', 'gospel', 'hip hop', 'house', 'indie rock', 'jazz', 'metal', \n",
    "                    'other', 'pop', 'punk rock', 'r&b', 'reggae', 'rock','rockabilly','soul', 'techno']\n",
    "\n",
    "# fetures to be outputed by the recommender at the end\n",
    "output_features = ['track_id', 'track_name', 'artist_name',  'core_genres', 'mood_goal']\n",
    "\n",
    "# target column\n",
    "target_feature = 'mood_goal'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data splits\n",
    "\n",
    "\n",
    "main_moosic_data_nk = split_dataset(moosic_data_samples, mood_categories = mood_categories, target_feature = target_feature,\n",
    "                        input_features = main_input_features,  output_features = output_features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X features (input):  X_train, X_test\n",
    "# Y features (output):  Y_train, Y_test\n",
    "# y feature (target):  y_train, y_test\n",
    "\n",
    "\n",
    "print(\"X train (input features) \")\n",
    "print(\"-----\"*10)\n",
    "Xm_train = main_moosic_data_nk['X_train']\n",
    "display(Xm_train.head(2))\n",
    "\n",
    "print(\"X test (input features) \")\n",
    "print(\"-----\"*10)\n",
    "Xm_test = main_moosic_data_nk['X_test']\n",
    "display(Xm_test.head(2))\n",
    "\n",
    "\n",
    "print(\"Y train (target output features) \")\n",
    "print(\"-----\"*10)\n",
    "Ym_train = main_moosic_data_nk['Y_train']\n",
    "display(Ym_train.head(2))\n",
    "\n",
    "\n",
    "print(\"Y test (target output features) \")\n",
    "print(\"-----\"*10)\n",
    "Ym_test = main_moosic_data_nk['Y_test']\n",
    "display(Ym_test.head(2))\n",
    "\n",
    "\n",
    "print(\"y train (target feature) \")\n",
    "print(\"-----\"*10)\n",
    "ym_train = main_moosic_data_nk['y_train']\n",
    "display(ym_train.head(2))\n",
    "\n",
    "\n",
    "print(\"y test (target feature) \")\n",
    "print(\"-----\"*10)\n",
    "ym_test = main_moosic_data_nk['y_test']\n",
    "display(ym_test.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xm_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# defining the actual y (target data - mood_goal)\n",
    "# y : y_train, y_test\n",
    "\n",
    "\n",
    "# encode categorical data : mood\n",
    "ym_train_dummies = pd.get_dummies(y_train, drop_first=True).replace({True: 1, False: 0})\n",
    "encoded_ym_train = pd.concat([ym_train, ym_train_dummies], axis=1)\n",
    "\n",
    "ym_test_dummies = pd.get_dummies(y_test, drop_first=True).replace({True: 1, False: 0})\n",
    "encoded_ym_test = pd.concat([ym_test, ym_test_dummies], axis=1)\n",
    "\n",
    "\n",
    "print(\"encoded target (train) data - mood_goal \")\n",
    "print(\"-----\"*10)\n",
    "display(encoded_ym_train.head(2))\n",
    "\n",
    "\n",
    "print(\"encoded target (test) data - mood_goal \")\n",
    "print(\"-----\"*10)\n",
    "display(encoded_ym_test.head(2))\n",
    "\n",
    "\n",
    "# mood_labels = [\"depressed\", \"sad\", \"anxious\",  \"neutral\", \"calm\", \"euphoric\", \"energetic\", \"happy\"]\n",
    "# mood_1d_class = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "\n",
    "# # add targets for evaluation for clusters later\n",
    "\n",
    "# moosic_data[\"mood_label\"] = (pd.cut(moosic_data[\"valence\"], bins=mood_valence_values, labels=mood_1d_labels)).astype('string')\n",
    "# moosic_data[\"mood_class\"] = (pd.cut(moosic_data[\"valence\"], bins=mood_valence_values, labels=mood_1d_class)).astype('Int64')\n",
    "\n",
    "# moosic_data.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xm_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "\n",
    "\n",
    "modelling_data = {\n",
    "    \n",
    "    'X_train' : Xm_train,\n",
    "    'X_test' : Xm_test,\n",
    "    'Y_train' : Ym_train,\n",
    "    'Y_test' : Ym_test,\n",
    "    'y_train' : ym_train,\n",
    "    'y_test' : ym_test,\n",
    "    'encoded_y_train' : encoded_ym_train,\n",
    "    'encoded_y_test' : encoded_ym_test\n",
    "\n",
    "    }\n",
    "\n",
    "\n",
    "main_cluster_params = {\n",
    "        'n_clusters' : 8,\n",
    "        'batch_size' : 500,\n",
    "        'random_state' : 42,\n",
    "        'init' : 'k-means++' \n",
    "    }\n",
    "\n",
    "# clf_params = {\n",
    "#         'n_estimators': [50, 100, 200],\n",
    "#         'learning_rate': [0.01, 0.1, 0.2],\n",
    "#         'max_depth': [None, 3, 8, 11, 20]\n",
    "#     }\n",
    "\n",
    "user_preferences = {'mood goal': 'relaxed', 'preferred_genre': 'hip hop'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mood_clusters  = {\n",
    "                        'happy' : 4,\n",
    "                        'euphoric' : 3,                  \n",
    "                        'tense' : 7, \n",
    "                        'angry' :0, \n",
    "                        'depressed' : 2, \n",
    "                        'sad' :6, \n",
    "                        'calm' : 1, \n",
    "                        'relaxed' : 5\n",
    "\n",
    "    }\n",
    "\n",
    "\n",
    "def moosic_clustering(Xm_train, playlist_length= 5, cluster_params = main_cluster_params, mood_clusters = mood_clusters,\n",
    "                        pca=False, tsne=True, sample_size = 10000, *args, **kwargs):\n",
    "\n",
    "\n",
    "    # model : clustering with mini-batch kmeans \n",
    "    clustered_data, clustered_embeddings, cluster_labels, cluster_centers = clustering_model(Xm_train,  pca = False, tsne = True, \n",
    "                                                                            params = main_cluster_params, sample_size = sample_size)\n",
    "\n",
    "\n",
    "    #scaled_embed = MinMaxScaler().fit_transform(clustered_embeddings)\n",
    "\n",
    "    # visualize the clustered data\n",
    "    fig, ax = plt.subplots(figsize = (16, 10))\n",
    "    \n",
    "\n",
    "    scaled_embed = MinMaxScaler().fit_transform(clustered_embeddings)\n",
    "    plt.scatter(scaled_embed[:, 0], scaled_embed[:, 1], c=cluster_labels, cmap=custom_cmap_quad)\n",
    "    #plt.scatter(cluster_centers[:, 0], cluster_centers[:, 1], marker='X', color='black') \n",
    "\n",
    "    # for cluster_centerx, cluster_centery in zip(cluster_centers[:, 0], cluster_centers[:, 1]):\n",
    "\n",
    "    #    plt.scatter(cluster_centerx, cluster_centery, marker='X', color='black') \n",
    "\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title('Music - Mood Clustered Data ', pad=15, fontsize = 20, weight = 'bold', color='#928d8d')#'#C3C7C5')\n",
    "    plt.colorbar()\n",
    "\n",
    "    get_axes = plt.gca()\n",
    "    plt.xticks([]) \n",
    "    plt.yticks([]) \n",
    "    xax = get_axes.axes.get_xaxis()\n",
    "    \n",
    "    xax = xax.set_visible(False)\n",
    "\n",
    "    yax = get_axes.axes.get_yaxis()\n",
    "    yax = yax.set_visible(False)\n",
    "\n",
    "    # Set the axis colors\n",
    "    ax.set_facecolor('#F7F3F0') #E2E2DB\n",
    "    ax.grid(color='#cfcecb')\n",
    "    ax.set_facecolor('#eeeeee') #eeeeee\n",
    "    ax.spines['bottom'].set_color('#eeeeee')\n",
    "    ax.spines['top'].set_color('#eeeeee')\n",
    "    ax.spines['right'].set_color('#eeeeee')\n",
    "    ax.spines['left'].set_color('#eeeeee')\n",
    "    ax.xaxis.label.set_color('#eeeeee')\n",
    "    ax.yaxis.label.set_color('#eeeeee')\n",
    "\n",
    "    plt.show()\n",
    "    plt.savefig('../images/3_clusters_main.png', transparent=True)\n",
    "\n",
    "\n",
    "    return clustered_data, clustered_embeddings, scaled_embed\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "\n",
    "main_clustered_data, main_clustered_embeddings, main_scaled_embeddings = moosic_clustering(Xm_train, playlist_length= 5, cluster_params = main_cluster_params, \n",
    "                                                                            mood_clusters = mood_clusters, pca=False, tsne=True, sample_size = 15000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_cluster_data = pd.concat([ Y_train, clustered_data['cluster_labels']], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m_cluster_data['mood_genre'] = m_cluster_data['mood_goal'] + ' ' + m_cluster_data['core_genres']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_cluster_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop null/empty rows\n",
    "\n",
    "null_rows111 = m_cluster_data[m_cluster_data.isnull().T.any()].index\n",
    "m_cluster_data = m_cluster_data.drop(null_rows111)\n",
    "empty_values1 = m_cluster_data.isna().sum()\n",
    "print(empty_values1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_cluster_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "track_mood_genre_vector = tfidf_vectorizer.fit_transform(m_cluster_data['mood_genre'])\n",
    "track_similarity_matrix = linear_kernel(track_mood_genre_vector, track_mood_genre_vector)\n",
    "track_similarity_data = pd.DataFrame(track_similarity_matrix, index=m_cluster_data['track_name'], columns=m_cluster_data['track_name'])\n",
    "track_similarity_data = track_similarity_data.reset_index(drop=True)\n",
    "track_similarity_data = track_similarity_data.rename_axis(None, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#m_cluster_data['mood_genre_vectors'] = track_mood_genre_vector\n",
    "mtrack_similarity_matrix = linear_kernel(track_mood_genre_vector, track_mood_genre_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# recommend top N = 5 or random N = 5 music track based on user preferences\n",
    "def moosic_recommender(main_clustered_data, main_clustered_embeddings, main_scaled_embeddings, Ym_train, user_preferences = {'mood': 'relaxed', 'genre': 'pop'},   \n",
    "                        playlist_length= 5, mood_clusters = mood_clusters, which_sim = 'mood', *args, **kwargs):\n",
    "\n",
    "    recommender_start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "    # get numerical representations of mood _genre vectors\n",
    "    tfidf_vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1, 2))\n",
    "\n",
    "    # user_preference = \" \".join(user_preferences.values())\n",
    "    user_preference = \" \".join(user_preferences['mood'].lower(), user_preferences['genre'].lower())\n",
    "    user_vector = tfidf_vectorizer.fit_transform(user_preferences['genre'])\n",
    "\n",
    "\n",
    "    # so as to query data based on user's preferences and clustered data\n",
    "\n",
    "    moosic_cluster_data = pd.concat([ Y_train, clustered_data['cluster_labels']], axis=1)\n",
    "    moosic_cluster_data['mood_genre'] = moosic_cluster_data['mood_goal'] + ' ' + moosic_cluster_data['core_genres']\n",
    "\n",
    "\n",
    "    ## track vectorization and track - to - track similarity computation\n",
    "\n",
    "    track_mood_genre_vector = tfidf_vectorizer.fit_transform(moosic_cluster_data['mood_genre'])\n",
    "    moosic_cluster_data['mood_genre_vectors'] = track_mood_genre_vector\n",
    "\n",
    "\n",
    "    clustered_moosic_tracks = moosic_cluster_data.groupby('mood_genre')['Features'].apply(list).reset_index()\n",
    "\n",
    "    # track to track similarity based on track_name\n",
    "    if which_sim == \"track_name\":\n",
    "        track_similarity_matrix = linear_kernel(track_mood_genre_vector, track_mood_genre_vector)\n",
    "        track_similarity_data = pd.DataFrame(track_similarity_matrix, index=moosic_cluster_data['track_name'], columns=moosic_cluster_data['track_name'])\n",
    "        track_similarity_data = track_similarity_data.reset_index(drop=True)\n",
    "        track_similarity_data = track_similarity_data.rename_axis(None, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    # track to track similarity based on mood_genre\n",
    "    if which_sim == \"mood\":\n",
    "        for mood_genre, _ in clustered_moosic_tracks:\n",
    "        # Compute similarity matrix within the mood_genre\n",
    "        similarity_matrix = linear_kernel(track_features)\n",
    "        similarity_matrices[genre] = similarity_matrix\n",
    "\n",
    "\n",
    "    # features track_similarity_data\n",
    "    tsd_features = track_similarity_data.columns.tolist()\n",
    "    scored_track_data = pd.concat([moosic_cluster_data, track_similarity_data], axis=1)\n",
    "\n",
    "    #mood_genre = f'{mood.lower()} {genre.lower()}'\n",
    "\n",
    "    # query track to track similarity moosic data based on user input\n",
    "    queried_user_data = scored_track_data.copy(deep = True)\n",
    "\n",
    "\n",
    "    # pickle dataframe:\n",
    "    import pickle\n",
    "    \n",
    "    with open('df.bin', 'wb') as f:\n",
    "        pickle.dump(queried_user_data, f, pickle.HIGHEST_PROTOCOL)\n",
    "    queried_user_data = (queried_user_data.query(\" mood_genre == @user_preference \")).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    ## - sort random N mood-music tracks by predicted probability for the category entered\n",
    "\n",
    "    moosic_randomN_idx = np.random.choice(\n",
    "                            queried_user_data.index,\n",
    "                            size = 5, #playlist_length,\n",
    "                            replace= False #random n = 5\n",
    "                            )\n",
    "\n",
    "    #recommended_moosic_playlist = queried_user_data[['track_id', 'track_name', 'artist_name']].iloc[moosic_randomN_idx]\n",
    "    recommended_moosic_playlist = queried_user_data[['track_id', 'track_name', 'artist_name']].iloc[:5]\n",
    "\n",
    "\n",
    "    recommender_end_time = time.time()\n",
    "    recommender_train_time = recommender_end_time - recommender_start_time\n",
    "    print(f\"Time taken for the recommender model : {recommender_train_time:.2f} seconds\")\n",
    "\n",
    "    #print(\"________\"*20)\n",
    "    #print(\"________\"*20)\n",
    "\n",
    "    return recommended_moosic_playlist, scored_track_data\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moosic_recommender(mood, genre, modelling_data = modelling_data, playlist_length= 5, cluster_params = baseline_cluster_params,\n",
    "                        pca=False, tsne=True, sample_size = 10000, *args, **kwargs):\n",
    "\n",
    "\n",
    "    # data : train, test features and targets\n",
    "    X_train, X_test = modelling_data['X_train'].drop(['key', 'speechiness',  'instrumentalness', 'tempo', 'acousticness'], axis =1), modelling_data['X_test'].drop(['key', 'speechiness',  'instrumentalness', 'tempo', 'acousticness'], axis =1)\n",
    "    Y_train, Y_test = modelling_data['Y_train'], modelling_data['Y_test']\n",
    "    y_train, y_test = modelling_data['y_train'], modelling_data['y_test']\n",
    "        \n",
    "    # get dummies\n",
    "    #encoded_y_train, encoded_y_test = modelling_data['encoded_y_train'], modelling_data['encoded_y_test']\n",
    "\n",
    "    # Label encoder\n",
    "    encoded_y_train, encoded_y_test = LabelEncoder().fit_transform(y_train), LabelEncoder().fit_transform(y_test)\n",
    "\n",
    "\n",
    "\n",
    "    # model : clustering with mini-batch kmeans \n",
    "    clustered_data, clustered_embeddings, cluster_labels, cluster_centers = clustering_model(X_train,  pca = False, tsne = True, \n",
    "                                                                            params = main_cluster_params, sample_size = 10000)\n",
    "\n",
    "\n",
    "    #scaled_embed = MinMaxScaler().fit_transform(clustered_embeddings)\n",
    "\n",
    "    # visualize the clustered data\n",
    "    fig, ax = plt.subplots(figsize = (16, 10))\n",
    "\n",
    "    scaled_embed = clustered_embeddings #MinMaxScaler().fit_transform(clustered_embeddings)\n",
    "    plt.scatter(scaled_embed[:, 0], scaled_embed[:, 1], c=cluster_labels, cmap=custom_cmap_hex1)\n",
    "\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title('Music - Mood Clustered Data ', pad=15, fontsize = 20, weight = 'bold', color='#2B2960')\n",
    "    plt.colorbar()\n",
    "\n",
    "    get_axes = plt.gca()\n",
    "    plt.xticks([]) \n",
    "    plt.yticks([]) \n",
    "    xax = get_axes.axes.get_xaxis()\n",
    "    \n",
    "    xax = xax.set_visible(False)\n",
    "\n",
    "    yax = get_axes.axes.get_yaxis()\n",
    "    yax = yax.set_visible(False)\n",
    "\n",
    "    # Set the axis colors\n",
    "    ax.set_facecolor('#E2E2DB') #E2E2DB\n",
    "    ax.spines['bottom'].set_color('#e3dfdb')\n",
    "    ax.spines['top'].set_color('#e3dfdb')\n",
    "    ax.spines['right'].set_color('#e3dfdb')\n",
    "    ax.spines['left'].set_color('#e3dfdb')\n",
    "    ax.xaxis.label.set_color('#605F5F')\n",
    "    ax.yaxis.label.set_color('#605F5F')\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    plt.savefig('../images/1_mainkclusters_plot.png', transparent=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # model recommender (classification/similarity and prediction/filter) part: \n",
    "\n",
    "    moosic_cluster_data = pd.concat([ Y_train, clustered_data['cluster_labels']], axis=1)\n",
    "    moosic_cluster_data['mood_genre'] = moosic_cluster_data['mood_goal'] + ' ' + moosic_cluster_data['core_genres']\n",
    "\n",
    "\n",
    "    ## track vectorization and track - to - track similarity computation\n",
    "\n",
    "    tfidf_vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1, 2))\n",
    "    track_mood_genre_vector = tfidf_vectorizer.fit_transform(moosic_cluster_data['mood_genre'])\n",
    "\n",
    "    track_similarity_matrix = linear_kernel(track_mood_genre_vector, track_mood_genre_vector)\n",
    "    track_similarity_data = pd.DataFrame(track_similarity_matrix, index=moosic_cluster_data['track_name'], columns=moosic_cluster_data['track_name'])\n",
    "    track_similarity_data = track_similarity_data.reset_index(drop=True)\n",
    "    track_similarity_data = track_similarity_data.rename_axis(None, axis=1)\n",
    "\n",
    "    # features track_similarity_data\n",
    "    tsd_features = track_similarity_data.columns.tolist()\n",
    "    scored_track_data = pd.concat([moosic_cluster_data, track_similarity_data], axis=1)\n",
    "\n",
    "    mood_genre = f'{mood.lower()} {genre.lower()}'\n",
    "\n",
    "    # query track to track similarity moosic data based on user input\n",
    "    queried_user_data = scored_track_data.copy(deep = True)\n",
    "    # pickle dataframe:\n",
    "    import pickle\n",
    "    \n",
    "    with open('df.bin', 'wb') as f:\n",
    "        pickle.dump(queried_user_data, f, pickle.HIGHEST_PROTOCOL)\n",
    "    queried_user_data = (queried_user_data.query(\" mood_genre == @mood_genre \")).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    ## - sort random N mood-music tracks by predicted probability for the category entered\n",
    "\n",
    "    moosic_randomN_idx = np.random.choice(\n",
    "                            queried_user_data.index,\n",
    "                            size = 5, #playlist_length,\n",
    "                            replace= False #random n = 5\n",
    "                            )\n",
    "\n",
    "    #recommended_moosic_playlist = queried_user_data[['track_id', 'track_name', 'artist_name']].iloc[moosic_randomN_idx]\n",
    "    recommended_moosic_playlist = queried_user_data[['track_id', 'track_name', 'artist_name']].iloc[:5]\n",
    "\n",
    "    return recommended_moosic_playlist, scored_track_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_preferences = {'mood goal': 'relaxed', 'preferred_genre': 'pop'}\n",
    "\n",
    "\n",
    "recommended_moosic_playlist, scored_track_data = moosic_recommender(user_preferences['mood goal'], user_preferences['preferred_genre'], modelling_data = modelling_data, playlist_length= 5, cluster_params = main_cluster_params, \n",
    "                            pca=False, tsne=True, sample_size = 10000)\n",
    "\n",
    "\n",
    "\n",
    "recommended_moosic_playlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_track_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_track_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from sklearn.metrics import rand_score, homogeneity_score, completeness_score, v_measure_score, silhouette_score\n",
    "\n",
    "\n",
    "print(rand_score(scored_track_data['mood_label'], scored_track_data['cluster_labels']))\n",
    "\n",
    "print(homogeneity_score(scored_track_data['mood_label'], scored_track_data['cluster_labels']))\n",
    "\n",
    "\n",
    "print(completeness_score(scored_track_data['mood_label'], scored_track_data['cluster_labels']))\n",
    "\n",
    "\n",
    "print(v_measure_score(scored_track_data['mood_label'], scored_track_data['cluster_labels']))\n",
    "\n",
    "print(silhouette_score(scored_track_data['mood_label'].to_numpy().reshape(-1,1), scored_track_data['cluster_labels'].to_numpy().reshape(-1,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def web_app_query(mood, genre, playlist_length = 5):\n",
    "    \n",
    "    playlist = moosic_recommender(mood, genre, modelling_data = modelling_data, playlist_length= playlist_length, cluster_params = main_cluster_params, \n",
    "                            pca=False, tsne=True, sample_size = 10000)\n",
    "\n",
    "    #return model\n",
    "    return playlist.to_dict('records')\n",
    "\n",
    "\n",
    "# model = web_app_query('calm', 'pop', playlist_length = 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_app_query('happy', 'pop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open('model.bin', 'wb') as f:\n",
    "    pickle.dump(web_app_query, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Delete prints\n",
    "* change dataframe into list of dicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_clustered_data, main_clustered_embeddings, main_scaled_embeddings = moosic_clustering(Xm_train, playlist_length= 5, cluster_params = main_cluster_params, \n",
    "                                                                            mood_clusters = mood_clusters, pca=False, tsne=True, sample_size = 20000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "params_kmodels = {\n",
    "    \n",
    "        'n_clusters': 2,\n",
    "        'init_kmode': ['Cao', 'Huang'], \n",
    "        'random_state': 42\n",
    "    \n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# functions\n",
    "# -- dimensionality reduction (tsne, umap, pca)\n",
    "# -- clustering models (kmeans, minibatch kmeans, kmode, minibatch kmode, kmeans + kmode, mean shift, dbscan)\n",
    "# -- text vectorization and similarity computation (tdidf vectorizer, cosine similarity, linear kernel)\n",
    "# -- classification models (xgboost, svm, logistic regression, naive bayes, random forest)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def dimensionality_reduction(dataset, method='tsne', n_components=2, random_state=42):\n",
    "\n",
    "    \"\"\"\n",
    "    Dimensionality reduction techniques\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    methods = {\n",
    "        'pca': PCA(n_components=n_components, random_state=random_state),\n",
    "        'tsne': TSNE(n_components=n_components, random_state=random_state),\n",
    "        'umap': UMAP(n_components=n_components, random_state=random_state)\n",
    "    }\n",
    "\n",
    "    if method in methods:\n",
    "        reduction_method = methods[method]\n",
    "        return reduction_method.fit_transform(dataset)\n",
    "    else:\n",
    "        raise ValueError(f\"The dimensionality reduction technique: '{method}' is currently not available.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def clustering_models(dataset, model='kmeans', n_clusters=2):\n",
    "\n",
    "    \"\"\"\n",
    "    Clustering models\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    models = {\n",
    "        'kmeans': KMeans(n_clusters),\n",
    "        'minibatch_kmeans': MiniBatchKMeans(n_clusters),\n",
    "        'kmode': KModes(n_clusters),\n",
    "        'kprototypes': KPrototypes(n_clusters),\n",
    "        'mean_shift': MeanShift(),\n",
    "        'dbscan': DBSCAN()\n",
    "    }\n",
    "\n",
    "    if model in models:\n",
    "        clustering_model = models[model]\n",
    "        return clustering_model.fit_predict(dataset)\n",
    "    else:\n",
    "        raise ValueError(f\"The clustering model : '{model}' model is currently not available.\")\n",
    "\n",
    "\n",
    "def text_processing(dataset, vectorizer='tfidf'):\n",
    "\n",
    "    \"\"\"\n",
    "    Similarity matrix computation - Text vectorization\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    vectorizers = {\n",
    "        'tfidf': lambda d: TfidfVectorizer().fit_transform(d),\n",
    "        'cosine_similarity': lambda d: cosine_similarity(d),\n",
    "        'linear_kernel': lambda d: linear_kernel(d)\n",
    "    }\n",
    "\n",
    "    if vectorizer in vectorizers:\n",
    "        text_vectorizer = vectorizers[vectorizer]\n",
    "        return text_vectorizer(dataset)\n",
    "    else:\n",
    "        raise ValueError(f\"The text vectorization method : '{vectorizer}' is currently not available.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def classification_models(dataset, labels, model='xgboost', random_state=42):\n",
    "\n",
    "    \"\"\"\n",
    "    Classification models\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    models = {\n",
    "        'xgboost': XGBClassifier(random_state=random_state),\n",
    "        'svm': SVC(random_state=random_state),\n",
    "        'logistic_regression': LogisticRegression(random_state=random_state),\n",
    "        'gaussian_naive_bayes': GaussianNB(),\n",
    "        'multinomial_naive_bayes': MultinomialNB(),\n",
    "        'random_forest': RandomForestClassifier(random_state=random_state),\n",
    "        'adaboost': AdaBoostClassifier(random_state=random_state),\n",
    "        'gradientboost': GradientBoostingClassifier(random_state=random_state)\n",
    "    }\n",
    "\n",
    "    if model in models:\n",
    "        classification_model = models[model]\n",
    "        return classification_model.fit(dataset, labels)\n",
    "    else:\n",
    "        raise ValueError(f\"The classification model: '{model}' model is currently not listed.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "# -- evaluation metrics (rand index, silhouette score, vmeasure score, ndcg, precision, recall)\n",
    "# -- \n",
    "# -- \n",
    "# -- \n",
    "# -- \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function clustering model (+ tsne) \n",
    "\n",
    "\n",
    "def pca_tsne(data,  pca = True, tsne=True, n_components=8, sample_size=5000, *args, **kwargs):\n",
    "\n",
    "\n",
    "    data = data.head(sample_size)\n",
    "    scaled_data = MinMaxScaler().fit_transform(data)\n",
    "    data_col = data.columns.to_list()\n",
    "    data = pd.DataFrame(scaled_data, columns = data_col)\n",
    "\n",
    "    if pca == True:\n",
    "        pca = PCA(n_components=2, random_state = 42)\n",
    "\n",
    "        pca_start_time = time.time()\n",
    "\n",
    "        data = MinMaxScaler().fit_transform(pca.fit_transform(data))\n",
    "\n",
    "        pca_end_time = time.time()\n",
    "        pca_train_time = pca_end_time - pca_start_time\n",
    "        print(f\"Time taken for dimensionality reduction using PCA: {pca_train_time:.2f} seconds\")\n",
    "\n",
    "        data = pd.DataFrame(data, columns = ['dimension_0', 'dimension_1'])\n",
    "\n",
    "\n",
    "\n",
    "    if tsne == True:\n",
    "        tsne = TSNE(n_components=2, random_state = 42)\n",
    "\n",
    "        tsne_start_time = time.time()\n",
    "\n",
    "        tsne_embeddings = tsne.fit_transform(data)\n",
    "\n",
    "        tsne_end_time = time.time()\n",
    "        tsne_train_time = tsne_end_time - tsne_start_time\n",
    "        \n",
    "    else:\n",
    "        data = data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return data, tsne_embeddings\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function clustering model (+ tsne) \n",
    "\n",
    "\n",
    "def clustering_model(data,  pca = True, tsne=True, params = {'n_clusters': 8}, sample_size=5000, *args, **kwargs):\n",
    "\n",
    "\n",
    "    data = data.head(sample_size)\n",
    "    scaled_data = MinMaxScaler().fit_transform(data)\n",
    "    data_col = data.columns.to_list()\n",
    "    data = pd.DataFrame(scaled_data, columns = data_col)\n",
    "\n",
    "    if pca == True:\n",
    "        pca = PCA(n_components=2, random_state = 42)\n",
    "\n",
    "        pca_start_time = time.time()\n",
    "\n",
    "        data = MinMaxScaler().fit_transform(pca.fit_transform(data))\n",
    "\n",
    "        pca_end_time = time.time()\n",
    "        pca_train_time = pca_end_time - pca_start_time\n",
    "        print(f\"Time taken for dimensionality reduction using PCA: {pca_train_time:.2f} seconds\")\n",
    "\n",
    "        data = pd.DataFrame(data, columns = ['dimension_0', 'dimension_1'])\n",
    "\n",
    "    else:\n",
    "        data = data\n",
    "\n",
    "\n",
    "    model = MiniBatchKMeans(**params)\n",
    "\n",
    "    kme_start_time = time.time()\n",
    "\n",
    "    data['cluster_labels'] = model.fit_predict(data)\n",
    "\n",
    "    kme_end_time = time.time()\n",
    "    kme_train_time = kme_end_time - kme_start_time\n",
    "    \n",
    "\n",
    "    cluster_labels = model.labels_ \n",
    "    cluster_centers = model.cluster_centers_ \n",
    "\n",
    "    #if tsne == True:\n",
    "    tsne = TSNE(n_components=2, random_state = 42)\n",
    "\n",
    "    tsne_start_time = time.time()\n",
    "\n",
    "    tsne_embeddings = tsne.fit_transform(data)\n",
    "\n",
    "    tsne_end_time = time.time()\n",
    "    tsne_train_time = tsne_end_time - tsne_start_time\n",
    "        \n",
    "\n",
    "    #else:\n",
    "    #    data = data\n",
    "\n",
    "\n",
    "    \n",
    "    # kp_model_name = \"minikmeans.pickle\"\n",
    "    # tp_model_name = \"tsne_embed.pickle\"\n",
    "\n",
    "    # pickle.dump(model, open(kp_model_name, 'wb'))\n",
    "    # pickle.dump(model, open(tp_model_name, 'wb'))\n",
    "\n",
    "\n",
    "    # kj_model_name = \"minikmeans.joblib\"\n",
    "    # tj_model_name = \"tsne_embed.joblib\"\n",
    "\n",
    "    # joblib.dump(model, kj_model_name)\n",
    "    # joblib.dump(model, tj_model_name)\n",
    "\n",
    "\n",
    "\n",
    "    return data, tsne_embeddings, cluster_labels, cluster_centers\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# classifier/prediction model\n",
    "# hyperparameter optimization\n",
    "\n",
    "\n",
    "\n",
    "def classifier_tuning(x_data, y_data, model_params, random_state=42, *args, **kwargs): # model_name = 'random forest',  *args, **kwargs):\n",
    "\n",
    "    classifiers = [\n",
    "        ('RandomForestClassifier', RandomForestClassifier()),\n",
    "        ('XGBClassifier', XGBClassifier()),\n",
    "        ('LinearSVC', LinearSVC()),\n",
    "        ('MultinomialNB', MultinomialNB()),\n",
    "        ('AdaBoostClassifier', AdaBoostClassifier()),\n",
    "        ('GradientBoostingClassifier', GradientBoostingClassifier())\n",
    "    ]\n",
    "\n",
    "    \n",
    "    cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "    best_classifiers = {}\n",
    "\n",
    "    for model_name, clf_model in classifiers: \n",
    "\n",
    "        cv_space = model_params[model_name]\n",
    "        #grid_search = GridSearchCV(classifiers, param_grid, cv=cv)\n",
    "        random_search = RandomizedSearchCV(clf_model, param_distributions=cv_space, n_iter=10,\n",
    "                                scoring='accuracy', n_jobs=-1, cv=cv, random_state=random_state)\n",
    "\n",
    "        random_search.fit(x_data, y_data)\n",
    "        best_classifiers[model_name] = random_search.best_estimator_\n",
    "\n",
    "        print(f\"The best hyperparameters for {model_name} are: \\n {random_search.best_params_}\")\n",
    "        print(f\"The best score for {model_name} is: {random_search.best_score_}\")\n",
    "\n",
    "        scores = cross_val_score(random_search, x_data, y_data, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "\n",
    "        print( f\" The {model_name} accuracy is : mean - {np.mean(scores):.3f} &  std - {np.std(scores):.3f} \" )\n",
    "\n",
    "    return best_classifiers\n",
    "\n",
    "\n",
    "\n",
    "# tune\n",
    "\n",
    "\n",
    "model_params = {\n",
    "    'RandomForestClassifier': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 3, 8, 11, 20],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'XGBClassifier': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [None, 3, 8, 11, 20]\n",
    "    },\n",
    "    'LinearSVC': {\n",
    "        'C': [0.1, 1.0, 10.0],\n",
    "        'penalty': ['l1', 'l2']\n",
    "    },\n",
    "    'MultinomialNB': {\n",
    "        'alpha': [0.01, 0.1, 1.0],\n",
    "        'fit_prior': [True, False]\n",
    "    },\n",
    "    'GradientBoostingClassifier': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [None, 3, 8, 11, 20]\n",
    "    },\n",
    "    'AdaBoostClassifier': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2]\n",
    "    },\n",
    "}\n",
    "\n",
    "#x_data = \n",
    "\n",
    "#y_data \n",
    "\n",
    "classifier_tuning(X_train, y_train['cluster_labels'], model_params, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis : clustering and classification metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error analysis : clustering and classification metrics\n",
    "\n",
    "\n",
    "def classification_metrics(ground_truth, predictions):\n",
    "\n",
    "    score_rocauc = roc_auc_score(ground_truth.to_numpy().reshape(-1,1), predictions.to_numpy().reshape(-1,1))\n",
    "    print(f\"ROC of: {score_rocauc:.2f} \")\n",
    "\n",
    "    score_acc = accuracy_score(ground_truth.to_numpy().reshape(-1,1), predictions.to_numpy().reshape(-1,1))\n",
    "    print(f\"ROC of: {score_acc:.2f} \")\n",
    "\n",
    "    score_report = classification_report(ground_truth.to_numpy().reshape(-1,1), predictions.to_numpy().reshape(-1,1))\n",
    "    print(f\"ROC of: {score_report:.2f} \")\n",
    "\n",
    "    score_matrix = confusion_matrix(ground_truth.to_numpy().reshape(-1,1), predictions.to_numpy().reshape(-1,1))\n",
    "    print(f\"ROC of: {score_matrix:.2f} \")\n",
    "\n",
    "    score_roc = roc_curve(ground_truth.to_numpy().reshape(-1,1), predictions.to_numpy().reshape(-1,1))\n",
    "    print(f\"ROC of: {score_roc:.2f} \")\n",
    "\n",
    "\n",
    "    scores = {\n",
    "        'roc_auc_score' : score_rocauc,\n",
    "        'accuracy_score' : score_acc,\n",
    "        'classification_report' : score_report,\n",
    "        'confusion_matrix' : score_matrix,\n",
    "        'roc_curve' : score_roc,\n",
    "        }\n",
    "    \n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# evaluation of models\n",
    "# - recommended music tracks based on mood and genre\n",
    "# - actual music track groupings based on mood and genre\n",
    "\n",
    "def clf_evaluation_metrics(predictions, ground_truth, playlist_length= 5, user_preferences = {'mood goal': 'relaxed', 'preferred_genre': 'hip hop'}):\n",
    "    \n",
    "    moosic_groups = set(ground_truth)\n",
    "    n_recommended = set(predictions[:playlist_length])\n",
    "    intersection = moosic_groups.intersection(n_recommended)\n",
    "\n",
    "    # precision at recommended playlist lenght, N = 5 (top n? random?)\n",
    "    precision_n = len(intersection) / playlist_length\n",
    "\n",
    "    # recall at recommended playlist lenght, N = 5 (top n? random?)\n",
    "    recall_n = len(intersection) / len(playlist_length)\n",
    "\n",
    "    # f1_score at recommended playlist lenght, N = 5 (top n? random?)\n",
    "    f1_form = 2 * (precision_n * recall_n) / (precision_n + recall_n)\n",
    "    f1_score_n = [0 if (p_n + r_n)==0 else f1_form for p_n, r_n in zip(precision_n, recall_n)]\n",
    "\n",
    "    # mean average precision (MAP) at recommended playlist lenght, N = 5 (top n? random?)\n",
    "    # map_n = lambda true_items, recommended_items, n: np.mean([precision_at_n(true_items, recommended_items, i + 1) \n",
    "    #                   for i, item in enumerate(recommended_items[:n]) if item in set(true_items)]) if any(item in set(true_items) for item in recommended_items[:n]) else 0\n",
    "    for i in range(playlist_length):\n",
    "        if any(predictions[i]) in moosic_groups:\n",
    "            map_n = np.mean([ len(intersection) for i in range(playlist_length)]) #if predictions[i] in moosic_groups ]) \n",
    "        else:\n",
    "            map_n = 0\n",
    "\n",
    "\n",
    "    # discounted cumulative gain (DCG) at recommended playlist lenght, N = 5 (top n? random?)\n",
    "    dcg_n = sum((2 ** 1 - 1) / np.log2(i + 2) for i, track in enumerate(predictions[:playlist_length]) if track in ground_truth)\n",
    "\n",
    "    # normalized discounted cumulative gain (NDCG) at recommended playlist lenght, N = 5 (top n? random?)\n",
    "    optimal_dcg_n = sum((2 ** 1 - 1) / np.log2(i + 2) for i, track in enumerate(predictions[:playlist_length]) if track in sorted(ground_truth, reverse=True))\n",
    "    ndcg_n  = [0 if optimal_dcg_n==0 else dcg_n / optimal_dcg_n]\n",
    "\n",
    "\n",
    "    eval_data = {\n",
    "        'user_preferences' : user_preferences,\n",
    "        'playlist_length' : playlist_length,\n",
    "        'predictions' : predictions,\n",
    "        'ground_truth' : ground_truth,\n",
    "        'moosic_groups' : moosic_groups,\n",
    "        'n_recommended' : n_recommended,\n",
    "        'intersection' : intersection,\n",
    "        'precision_n' : precision_n,\n",
    "        'recall_n' : recall_n,\n",
    "        'f1_score_n' : f1_score_n,\n",
    "        'map_n' : map_n,\n",
    "        'dcg_n' : dcg_n,\n",
    "        'optimal_dcg_n' : optimal_dcg_n,\n",
    "        'ndcg_n' : ndcg_n\n",
    "        }\n",
    "\n",
    "\n",
    "    return eval_data\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# User data - test\n",
    "\n",
    "|  user_id  |  user_name  | preferred_genre | mood_goal | previous_choices |\n",
    "|:---------:|:-----------:|:---------------:|:---------:|:----------------:|\n",
    "|  m1m0h0  |  apollo  | hip hop | happy | ['new age', 'any'] |\n",
    "|  m1m0h1  |  egwu | any | euphoric | ['electronic', 'tense'] |\n",
    "|  m1m0h2  |  aurras   | folk | sad | ['world/traditional', 'euphoric'] |\n",
    "|  m1m0h3  |  pelios  | jazz | tense | ['country', 'relaxed'] |\n",
    "|  m1m0h4  |  inuaria  | metal | calm | ['blues', 'angry'] |\n",
    "|  m1m0h5  |  psyche  | blues | depressed | ['any', 'happy'] |\n",
    "|  m1m0h6  |  ihy  | pop | any | ['folk', 'sad'] |\n",
    "|  m1m0h7  |  ova  | rock | angry | ['jazz, 'relaxed'] |\n",
    "|  m1m0h8  |  thalia  | any | relaxed | ['hip hop', 'calm'] |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "user_preferences = {'mood goal': ['relaxed', 'tense'], 'preferred_genre': ['hip hop', 'folk']}\n",
    "user_test_data = pd.DataFrame([user_preferences])\n",
    "\n",
    "user_test_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Initial analysis of the metrics\n",
    "\n",
    "For the mini-batch kmeans clustering with:  \n",
    "* rand_score of: 0.78  means the model is good (okay) with respect to the true mood_class\n",
    "* fowlkes_mallows_score of: 0.17 , bad or moderate cluster prediction by the model?\n",
    "* homogeneity_score of: 0.09, low score indicates the clusters are not highly homogeneous with respect to the predicted mood_class labels \n",
    "* completeness_score of: 0.09, low score indicates that some data points of the same class are split across predicted by the model clusters \n",
    "* v_measure_score of: 0.09 , okay/bad? quality of clustering\n",
    "* mutual_info_score of: 0.18, an okay level of shared information \n",
    "* adjusted_rand_score of: 0.04 , low level beyond what is expected by chance\n",
    "* adjusted_mutual_info_score of: 0.09 , low/okay level of agreement beyond what is expected by chance\n",
    "\n",
    "<br>\n",
    "\n",
    "For the mini-batch kmeans clustering with:  \n",
    "* silhouette_score of: -0.22 , negative, the clusters overlap and are not well separated\n",
    "* calinski_harabasz_score of: 2729.40 , better separation between clusters? , low within-cluster variance due to high value\n",
    "\n",
    "<br>\n",
    "\n",
    "* rand_score measures: the similarity of the predicted clusters and the true clusters for the mood music data, 0 (not a good match/clustering) to 1 (perfect identical to true clusters) \n",
    "* fowlkes_mallows_score: the similarity of the predicted clusters and the true clusters for the mood music data, 0 (not a good match/clustering) to 1 (perfect) \n",
    "* homogeneity_score: a measure of how much each cluster contains only data points that belong to a single class\n",
    "* completeness_score: a measure of how well all cluster data points that belong to the same class are assigned to the same cluster\n",
    "* v_measure_score: the harmonic mean of homogeneity and completeness, a balanced measure of the quality of clusters \n",
    "* mutual_info_score: the measure of the amount of information shared between true and predicted clusters\n",
    "* adjusted_rand_score: a variation of the rand index score that accounts for chance\n",
    "* adjusted_mutual_info_score: a variation of the mutual info score that accounts for chance\n",
    "* silhouette_score : it measures the quality of clusters by evaluating how similar each data point is to its own cluster compared to other clusters\n",
    "* calinski_harabasz_score: the variance ratio criterion, it measures the cluster quality based on between-cluster and within-cluster variance\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "In summary, the model \n",
    "\n",
    "* was able to cluster 78% of the data to the right mood clusters for the music tracks based on valence and other audio features\n",
    "* thus the baseline model predicted clusters is approximately 78 % similar to the actual music-mood (1-D) clusters\n",
    "* also show that clusters are not well separated and a lot of music data belonging to similar clusters were not sisigned to the same ones\n",
    "* the music tracks smaples seem to belong to multiple mood classes\n",
    "\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity between the predicted and actual mood clusters\n",
    "# by what percentage are they similar?\n",
    "# rand index score of 0.78\n",
    "# in terms of % \n",
    "\n",
    "RI = 0.82\n",
    "RI_rate = RI * 100\n",
    "print(f\"The similarity rate between predicted and true clusters is {RI_rate:.2f} %\")\n",
    "print(f\"The baseline model predicted clusters is approximately {RI_rate:.2f} % similar to the actual music-mood (1-D) clusters\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
